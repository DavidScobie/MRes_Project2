{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import mapvbvd\n",
    "from bart import bart\n",
    "from matplotlib import pyplot as plt\n",
    "import cfl\n",
    "import PlotUtils"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\"\"\"\n",
    "Load Data \n",
    "\"\"\"\n",
    "fullfile='/media/sf_ML_work/BART/rawData_exercise/meas_MID00573_FID48984_rest_stack.dat'\n",
    "\n",
    "twixObj = mapvbvd.mapVBVD(fullfile)\n",
    "sizeObj = len(twixObj)\n",
    "twixObj[sizeObj-1].image.flagRemoveOS = False\n",
    "\n",
    "data_hdr = twixObj[sizeObj-1].hdr\n",
    "\n",
    "noSlices = int(data_hdr.Config.NSlc)\n",
    "matrix = int(data_hdr.Config.ImageColumns)\n",
    "nPhases = int(data_hdr.Config.NPhs)\n",
    "accSpokes = int(data_hdr.Config.RadialViews)\n",
    "\n",
    "del data_hdr\n",
    "print(noSlices)\n",
    "\"12\"\n",
    "print(matrix) \n",
    "\"192\"\n",
    "print(nPhases) \n",
    "\"40\"\n",
    "print(accSpokes) \n",
    "\"13\"\n",
    "\n",
    "\"--------------------------------------\"\n",
    "\"  data_hdr = twixObj[sizeObj-1].hdr \"\n",
    "\"current size 384 26 13 1 12 1 40\"\n",
    "\n",
    "raw_data = np.squeeze(twixObj[sizeObj-1].image[:,:,:,:,:,:,:,:,:,:])\n",
    "print(\"raw_data size = \", raw_data.shape)\n",
    "\" (384, 26, 13, 12, 40) \"\n",
    "\n",
    "\"----------------------------------------------\"\n",
    "\n",
    "if noSlices == 1 :\n",
    "    raw_data = np.permute(raw_data, [0, 1, 2, 4, 3])\n",
    "\n",
    "nCoils = len(raw_data[1])\n",
    "print(\" nCoils = \", nCoils)\n",
    "\n",
    "\"\"\"\n",
    "% raw_data is currently stored in the format of:\n",
    "%    matrix*2 (due to 2x OverSampling in readout directiom);\n",
    "%    nCoils\n",
    "%    accSpokes\n",
    "%    noSlices\n",
    "%    nPhases\n",
    "\n",
    "% so in this case [384, 26, 13, 12, 40]\n",
    "\n",
    "% reorder here just so that i can do gridding per 2D slice on each coil\n",
    "% seperately\n",
    "%data_image is now to be stored in the format of:\n",
    "%    matrix*2 (due to 2x OverSampling in readout directiom);\n",
    "%    accSpokes\n",
    "%    nPhases\n",
    "%    nCoils\n",
    "%    noSlices\n",
    "\n",
    "% so in this case [384, 13, 40, 26, 12]\n",
    "\"\"\"\n",
    "raw_data = np.transpose(raw_data, [0, 2, 4, 1, 3])\n",
    "print(\"raw_data = \", raw_data.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "pymapVBVD version 0.4.2\n",
      "Software version: VD\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Scan 3/3, read all mdhs: 562MB [00:01, 385MB/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12\n",
      "192\n",
      "40\n",
      "13\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "raw_data size =  (384, 26, 13, 12, 40)\n",
      " nCoils =  26\n",
      "raw_data =  (384, 13, 40, 26, 12)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "\"now calculate the trajectory - get the radial angles from the raw data file\"\n",
    "\"------------------------------------------------------\"\n",
    "\n",
    "uint16Angle0 = np.uint16(twixObj[sizeObj-1].image.iceParam[:,4])  #why are there 4 angles?\n",
    "uint16Angle1 = np.uint16(twixObj[sizeObj-1].image.iceParam[:,5])\n",
    "uint16Angle2 = np.uint16(twixObj[sizeObj-1].image.iceParam[:,6]) \n",
    "uint16Angle3 = np.uint16(twixObj[sizeObj-1].image.iceParam[:,7]) \n",
    "\n",
    "del twixObj\n",
    "del sizeObj\n",
    "\n",
    "tt1=np.stack((uint16Angle0, uint16Angle1, uint16Angle2, uint16Angle3)) #the 4 angles get stacked together\n",
    "print(\"\\n len(uint16Angle0) = \", len(uint16Angle0), \" tt1= \", tt1.shape)\n",
    "\n",
    "del uint16Angle0\n",
    "del uint16Angle1\n",
    "del uint16Angle2\n",
    "del uint16Angle3\n",
    "\n",
    "radialAngles = []\n",
    "for i in range(accSpokes*nPhases) : #range 520\n",
    "    tt4 = np.array(tt1[:, i], dtype=np.uint16)\n",
    "    radialAngles.append(tt4.view(np.double)) #radial angles is what we make from the angles of the .dat file\n",
    "\n",
    "del tt1\n",
    "del tt4\n",
    "del i #the temporary ones get deleted\n",
    "\"\"\" \n",
    "  print(\"ii = \", i, \" , \", tt4, \" , \", combinedAngle[i]) \n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "\" now create trajectory as used in the sequence, to match the above data \"\n",
    "    \n",
    "npoints = accSpokes * (matrix*2) * nPhases; # (13x192x2x40) = 199680, why do we multiply this by 13?\n",
    "dimensions  = 3\n",
    "\n",
    "trajectory = np.zeros((dimensions, matrix*2, accSpokes, nPhases)) #(3,384,13,40) this is number of points\n",
    "\" weights    = np.zeros((matrix*2, accSpokes, nPhases))\"\n",
    "\n",
    "for phs in range(nPhases) : #40\n",
    "    for lin in range(accSpokes) : #13 \n",
    "        ang = radialAngles[phs*accSpokes + lin] #(0:39 x 13) + (0:12), goes up to 519\n",
    "\n",
    "        cos_angle = math.cos(ang)\n",
    "        sin_angle = math.sin(ang)\n",
    "             \n",
    "        for col in range(matrix*2) : #384\n",
    "            kx = (col - matrix) /2  #(0:383 - 192) /2 because of the 2x oversampling\n",
    "                \n",
    "            trajectory[0, col, lin, phs]=(cos_angle*kx) #fill kx up with angles. (-192:192) \n",
    "            trajectory[1, col, lin, phs]=(sin_angle*kx) #(-192:192) \n",
    "            trajectory[2, col, lin, phs]=0.0 #kz = 0\n",
    "            \"\"\"            \n",
    "            if kx == 0.0 :\n",
    "                weights[col, lin, phs]= 0.25 \n",
    "            else :\n",
    "                weights[col, lin, phs]=  abs(kx) \n",
    "            \"\"\"\n",
    "del sin_angle\n",
    "del cos_angle\n",
    "del col \n",
    "del phs\n",
    "del lin  \n",
    "del kx       "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " len(uint16Angle0) =  6240  tt1=  (4, 6240)\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "GRIDresult = np.zeros((matrix, matrix, nPhases, noSlices)) # (192,192,40,12)\n",
    "\n",
    "noSlices = 1\n",
    "for sl in range(noSlices) : #range 12\n",
    "    sliceData = raw_data[:,:,:,:,sl] #[384, 13, 40, 26, 1] , why do we have the 13 in here? \n",
    "\n",
    "    print(\"sliceData \", sliceData.shape)\n",
    "    dataCoilSensitivities = np.zeros((matrix*2, accSpokes*nPhases, 1, nCoils), dtype=complex) #(384,520,1,26) each of the k space points has its own sensitivity!\n",
    "    trajScale = np.zeros((dimensions, matrix*2, accSpokes*nPhases)) #(3,384,520)\n",
    "\n",
    "    \" calculate coil sensitivities \"\n",
    "    \" this stacks up the data over all time points, as we do a temporal average to get a fully sampled equivalent image to calculate the CS from\"\n",
    "    for ph in range(nPhases) : #40\n",
    "        dataCoilSensitivities[:,ph*accSpokes:(ph+1)*accSpokes, 0, :] = np.squeeze(sliceData[:,:,ph,:]) #remove the [...,1] dimension from the end of sliceData. we are just reshaping here effectively\n",
    "        trajScale[:,:,ph*accSpokes:(ph+1)*accSpokes] = trajectory[:,:,:, ph] #saving the trajectory of each slice as 3D matrix instead of 4D\n",
    "\n",
    "    dataCS_3124 = np.transpose(dataCoilSensitivities, [2, 0, 1, 3]) #permute and save raw data as another variable before deletion\n",
    "    del dataCoilSensitivities\n",
    "    del ph\n",
    "\n",
    "    \"grid the data\"\n",
    "    \"David: you need to chnage the following line to your gridder!!!!\"\n",
    "    print('trajScale',np.shape(trajScale),'dataCS_3124',np.shape(dataCS_3124))\n",
    "\n",
    "    import tensorflow_nufft as tfft\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    #reshape the raw data\n",
    "    dataCS_perm = tf.transpose(dataCS_3124, perm=[3,0,1,2])\n",
    "    dataCS_perm =  tf.reshape(dataCS_perm , [nCoils, -1])\n",
    "    print('dataCS_perm',tf.shape(dataCS_perm))\n",
    "\n",
    "    #reshape the trajectory data\n",
    "    trajSc = trajScale[0:2,:,:] #making it (2,384,520)\n",
    "    print('traj_scale',tf.shape(trajSc))\n",
    "    trajSc= tf.transpose(trajSc, perm=[1,2,0])\n",
    "    trajSc =  tf.reshape(trajSc , [-1 , 2])\n",
    "    trajSc = tf.expand_dims(trajSc,axis=0)\n",
    "    trajSc = tf.repeat(trajSc, repeats = 26, axis = 0)\n",
    "\n",
    "    #scale from -pi to pi\n",
    "    trajSc = (trajSc / 192) *2*np.pi\n",
    "    print('trajSc',tf.shape(trajSc), 'max traj', np.max(trajSc), 'min traj', np.min(trajSc))\n",
    "\n",
    "    # #try with just the first coil data\n",
    "    # dataCS_perm = dataCS_3124[:,:,:]\n",
    "    # dataCS_perm =  tf.reshape(dataCS_perm , [-1])\n",
    "    # print('dataCS_perm',tf.shape(dataCS_perm))\n",
    "\n",
    "    # trajSc= tf.transpose(trajScale, perm=[1,2,0])\n",
    "    # trajSc =  tf.reshape(trajSc , [-1 , 3])\n",
    "    # trajSc = (trajSc / 192) *2*np.pi\n",
    "    # print('trajSc',tf.shape(trajSc), 'max traj', np.max(trajSc), 'min traj', np.min(trajSc))\n",
    "    # data = tfft.nufft(freq, traj, transform_type='type_1', fft_direction='backward', grid_shape=oshape)\n",
    "    average_gridded_data = tfft.nufft(dataCS_perm , trajSc, transform_type='type_1', fft_direction='backward', grid_shape=(40,192,192))\n",
    "    print(\"average_gridded_data = \", average_gridded_data.shape)\n",
    "    average_gridded_data = tf.math.reduce_sum(average_gridded_data,axis = 1)\n",
    "    print('average_gridded_data',tf.shape(average_gridded_data), 'max avg', np.max(average_gridded_data), 'min avg', np.min(average_gridded_data))\n",
    "    average_gridded_data= tf.transpose(average_gridded_data, perm=[1,2,0]) #big set\n",
    "    print(\"average_gridded_data = \", average_gridded_data.shape)\n",
    "    # average_gridded_data = bart(1,\"nufft -i -d\"+str(matrix)+\":\"+str(matrix)+\":1\", trajScale, dataCS_3124) #The bart nufft\n",
    "    # average_gridded_data= tf.transpose(average_gridded_data, perm=[2,3,1,0])\n",
    "    # print(\"average_gridded_data = \", average_gridded_data.shape)\n",
    "    \" size (192x192x1x26)\"\n",
    "\n",
    "    \" this part is fine \"\n",
    "    # fig, ax = plt.subplots(nrows=1,ncols=4, figsize=(10,10))\n",
    "    # # for cl in range(4) :\n",
    "    # for cl in range(0) :\n",
    "    #     # ax[cl].imshow(abs(average_gridded_data[:,:,0, cl]))\n",
    "    #     ax[cl].imshow(abs(average_gridded_data[:,:]))\n",
    "    # \"  \"\n",
    "    # del dataCS_3124\n",
    "    plt.figure(0)\n",
    "    plt.imshow(abs(average_gridded_data[:,:,0]))\n",
    "    plt.show()\n",
    "\n",
    "#     ksp = bart(1, \"fft -u 7\", average_gridded_data)\n",
    "#     del average_gridded_data\n",
    "\n",
    "#     coil_sensitivities = bart(1, \"caldir 20\", ksp)\n",
    "#     \" coil_sensivitoes = np.squeeze(coil_sensitivities) \"\n",
    "#     del ksp\n",
    "#     \" plot coil sensitivities\"\n",
    "#     print(\"sl = \", sl, \" , cS size = \", coil_sensitivities.shape)\n",
    "#     fig, ax = plt.subplots(nrows=1, ncols=5,figsize=(10,10))\n",
    "#     for cl in range(5) :\n",
    "#         ax[cl].imshow(abs(coil_sensitivities[:,:,0,cl]))\n",
    "#     \" \"\n",
    "    \n",
    "#     \" ---------------------------------------------- \"\n",
    "#     \"now grid the data\"\n",
    "\n",
    "#     \" slice data is currently [matrix*2, accSpokes, nCoils, nPhases] \"\n",
    "#     for ph in range(2) :\n",
    "#         \"nPhases) :\"\n",
    "\n",
    "#         dataAll = np.zeros((matrix*2, accSpokes, 1, nCoils),dtype=complex)\n",
    "#         trajAll = np.zeros((dimensions, matrix*2, accSpokes))\n",
    "\n",
    "#         dataAll[:,:,0,:] = np.squeeze(sliceData[:,:,ph,:])\n",
    "#         trajAll[:,:,:] = trajectory[:,:,:, ph]\n",
    "\n",
    "#         dataAll_3124 = np.transpose(dataAll, [2, 0, 1, 3]) \n",
    "#         del dataAll\n",
    "\n",
    "#         \"grid the data\"\n",
    "#         \"David: you need to chnage the following line to your gridder!!!!\"\n",
    "#         gridded_data = bart (1,\"nufft -i -d\"+str(matrix)+\":\"+str(matrix)+\":1\", trajAll, dataAll_3124)\n",
    "#         print(\"gridded_data = \", gridded_data.shape)\n",
    "#         \" size (192x192x1x26)\"\n",
    "#         del dataAll_3124\n",
    "#         del trajAll\n",
    "\n",
    "#         gridded_data2=np.squeeze(np.transpose(gridded_data, [0, 1, 3, 2]))\n",
    "\n",
    "#         print(\"ph = \", ph  )\n",
    "#         fig, ax = plt.subplots(nrows=2, figsize=(6,10))\n",
    "#         ax[0].imshow(np.squeeze(abs(gridded_data2[:,:,20])), vmin=0, vmax =0.0001)\n",
    "\n",
    "#         \"\"\"   \n",
    "#         print(\"gridded_data2 = \", gridded_data2.shape)\n",
    "#         print(\"coil_sensitivities = \", coil_sensitivities.shape)\n",
    "#         weightedData = abs(np.multiply(gridded_data2, np.conjugate(np.squeeze(coil_sensitivities))))\n",
    "#         print(\"weigghtedData = \", weightedData.shape)\n",
    "     \n",
    "#         tempData = np.sum(weightedData, axis=2) \n",
    "#         print(\"tempData = \", tempData.shape)\n",
    "      \n",
    "#         GRIDresult[:,:,ph,sl] = abs(tempData)\n",
    "#         \"\"\"  \n",
    "#     del ph  \n",
    "#     \"\"\"\n",
    "#     print(\"sl = \", sl  )\n",
    "#     fig, ax = plt.subplots(nrows=5, figsize=(6,10))\n",
    "#     for ph in range(5) :\n",
    "#         ax[ph].imshow(np.squeeze(abs(GRIDresult[:,:,ph,sl])), vmin=0, vmax =0.001)\n",
    "#     \" ---------------------------------------------- \"\n",
    "#     \"\"\"\n",
    "#     del coil_sensitivities\n",
    "    \n",
    "# del dimensions\n",
    "# del radialAngles"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sliceData  (384, 13, 40, 26)\n",
      "trajScale (3, 384, 520) dataCS_3124 (1, 384, 520, 26)\n",
      "dataCS_perm tf.Tensor([    26 199680], shape=(2,), dtype=int32)\n",
      "traj_scale tf.Tensor([  2 384 520], shape=(3,), dtype=int32)\n",
      "trajSc tf.Tensor([    26 199680      2], shape=(3,), dtype=int32) max traj 3.1415552722034468 min traj -3.141592653589793\n",
      "average_gridded_data =  (26, 192, 192)\n",
      "average_gridded_data tf.Tensor([ 26 192], shape=(2,), dtype=int32) max avg (788.6063865593732-354.6774704911169j) min avg (-429.80165815652464-379.1286246802765j)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-13 22:24:18.370510: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at transpose_op.cc:143 : Invalid argument: transpose expects a vector of size 2. But input(1) is a vector of size 3\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "InvalidArgumentError",
     "evalue": "transpose expects a vector of size 2. But input(1) is a vector of size 3 [Op:Transpose]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3214/1860060339.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0maverage_gridded_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_gridded_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'average_gridded_data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_gridded_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'max avg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_gridded_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'min avg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_gridded_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0maverage_gridded_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_gridded_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#big set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average_gridded_data = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_gridded_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# average_gridded_data = bart(1,\"nufft -i -d\"+str(matrix)+\":\"+str(matrix)+\":1\", trajScale, dataCS_3124) #The bart nufft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mtranspose_v2\u001b[0;34m(a, perm, conjugate, name)\u001b[0m\n\u001b[1;32m   2225\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2226\u001b[0m   \"\"\"\n\u001b[0;32m-> 2227\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconjugate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconjugate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(a, perm, name, conjugate)\u001b[0m\n\u001b[1;32m   2306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2307\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mperm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2308\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtranspose_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2310\u001b[0m     \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtranspose\u001b[0;34m(x, perm, name)\u001b[0m\n\u001b[1;32m  11645\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11646\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11647\u001b[0;31m       return transpose_eager_fallback(\n\u001b[0m\u001b[1;32m  11648\u001b[0m           x, perm, name=name, ctx=_ctx)\n\u001b[1;32m  11649\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mtranspose_eager_fallback\u001b[0;34m(x, perm, name, ctx)\u001b[0m\n\u001b[1;32m  11670\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11671\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"T\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Tperm\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_Tperm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11672\u001b[0;31m   _result = _execute.execute(b\"Transpose\", 1, inputs=_inputs_flat,\n\u001b[0m\u001b[1;32m  11673\u001b[0m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[1;32m  11674\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: transpose expects a vector of size 2. But input(1) is a vector of size 3 [Op:Transpose]"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}